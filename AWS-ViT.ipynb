{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73d5bc93",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ad82828",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: _moduleraw: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `_moduleraw'\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: tensorflow in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (2.8.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorflow) (1.43.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorflow) (60.0.4)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.20 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: libclang>=9.0.1 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorflow) (4.0.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorflow) (0.24.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.10.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: zipp>=0.5 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.1.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/tensorflow2_p37/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow --pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67d76472",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: _moduleraw: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `_moduleraw'\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: tensorflow-addons in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (0.15.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in ./anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages (from tensorflow-addons) (2.13.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/tensorflow2_p37/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2_p37/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.5.0 and strictly below 2.8.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b9e626",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ce12bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100523f0",
   "metadata": {},
   "source": [
    "# hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f2a2bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "image_size = 32\n",
    "n_classes = 10\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 256\n",
    "num_epochs = 20\n",
    "patch_size = 4\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 5\n",
    "transformer_units = [projection_dim * 2, projection_dim]\n",
    "transformer_layers = 6\n",
    "mlp_head_units = [512, 128]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53a1689",
   "metadata": {},
   "source": [
    "# data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be23f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5de086",
   "metadata": {},
   "source": [
    "# how we split images into patches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ef612e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch size: 4 X 4\n",
      "Patches per image: 64\n",
      "Elements per patch: 48\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 64 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mlp(x, hidden_units):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches  \n",
    "    \n",
    "    \n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded\n",
    "    \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
    "plt.imshow(image.astype(\"uint8\"))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "patches = Patches(patch_size)(tf.convert_to_tensor([image]))\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
    "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2faa6d0",
   "metadata": {},
   "source": [
    "# define vision transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d53d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier():\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(inputs)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim)(x1, x1)\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        x3 = mlp(x3, hidden_units=transformer_units)\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    features = mlp(representation, hidden_units=mlp_head_units)\n",
    "    logits = layers.Dense(n_classes)(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573ef3a",
   "metadata": {},
   "source": [
    "# train and test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d208aed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "176/176 [==============================] - 175s 958ms/step - loss: 1.6088 - accuracy: 0.4272 - val_loss: 1.3010 - val_accuracy: 0.5366\n",
      "Epoch 2/20\n",
      "176/176 [==============================] - 171s 970ms/step - loss: 1.2232 - accuracy: 0.5625 - val_loss: 1.1523 - val_accuracy: 0.5938\n",
      "Epoch 3/20\n",
      "176/176 [==============================] - 168s 955ms/step - loss: 1.0547 - accuracy: 0.6248 - val_loss: 0.9609 - val_accuracy: 0.6596\n",
      "Epoch 4/20\n",
      "176/176 [==============================] - 171s 969ms/step - loss: 0.9388 - accuracy: 0.6690 - val_loss: 0.9150 - val_accuracy: 0.6738\n",
      "Epoch 5/20\n",
      "176/176 [==============================] - 172s 976ms/step - loss: 0.8334 - accuracy: 0.7047 - val_loss: 0.9150 - val_accuracy: 0.6782\n",
      "Epoch 6/20\n",
      "176/176 [==============================] - 169s 962ms/step - loss: 0.7570 - accuracy: 0.7342 - val_loss: 0.8398 - val_accuracy: 0.7096\n",
      "Epoch 7/20\n",
      "176/176 [==============================] - 171s 973ms/step - loss: 0.6936 - accuracy: 0.7551 - val_loss: 0.8156 - val_accuracy: 0.7150\n",
      "Epoch 8/20\n",
      "176/176 [==============================] - 162s 918ms/step - loss: 0.6332 - accuracy: 0.7753 - val_loss: 0.7699 - val_accuracy: 0.7344\n",
      "Epoch 9/20\n",
      "176/176 [==============================] - 159s 902ms/step - loss: 0.5865 - accuracy: 0.7929 - val_loss: 0.7684 - val_accuracy: 0.7414\n",
      "Epoch 10/20\n",
      "176/176 [==============================] - 157s 892ms/step - loss: 0.5491 - accuracy: 0.8055 - val_loss: 0.7957 - val_accuracy: 0.7370\n",
      "Epoch 11/20\n",
      "176/176 [==============================] - 157s 894ms/step - loss: 0.5096 - accuracy: 0.8222 - val_loss: 0.7952 - val_accuracy: 0.7336\n",
      "Epoch 12/20\n",
      "176/176 [==============================] - 156s 887ms/step - loss: 0.4691 - accuracy: 0.8359 - val_loss: 0.7817 - val_accuracy: 0.7390\n",
      "Epoch 13/20\n",
      "176/176 [==============================] - 155s 884ms/step - loss: 0.4392 - accuracy: 0.8454 - val_loss: 0.7983 - val_accuracy: 0.7392\n",
      "Epoch 14/20\n",
      "176/176 [==============================] - 156s 884ms/step - loss: 0.4117 - accuracy: 0.8564 - val_loss: 0.8127 - val_accuracy: 0.7364\n",
      "Epoch 15/20\n",
      "176/176 [==============================] - 155s 882ms/step - loss: 0.3834 - accuracy: 0.8672 - val_loss: 0.7839 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "176/176 [==============================] - 155s 884ms/step - loss: 0.3570 - accuracy: 0.8760 - val_loss: 0.7940 - val_accuracy: 0.7524\n",
      "Epoch 17/20\n",
      "176/176 [==============================] - 155s 881ms/step - loss: 0.3422 - accuracy: 0.8821 - val_loss: 0.8005 - val_accuracy: 0.7526\n",
      "Epoch 18/20\n",
      "176/176 [==============================] - 154s 878ms/step - loss: 0.3133 - accuracy: 0.8918 - val_loss: 0.8116 - val_accuracy: 0.7484\n",
      "Epoch 19/20\n",
      "176/176 [==============================] - 155s 880ms/step - loss: 0.3026 - accuracy: 0.8952 - val_loss: 0.7964 - val_accuracy: 0.7596\n",
      "Epoch 20/20\n",
      "176/176 [==============================] - 155s 878ms/step - loss: 0.2820 - accuracy: 0.9028 - val_loss: 0.8659 - val_accuracy: 0.7488\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 0.8294 - accuracy: 0.7503\n",
      "Test accuracy: 75.03%\n"
     ]
    }
   ],
   "source": [
    "def run_experiment(model):\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "vit_classifier = create_vit_classifier()\n",
    "history = run_experiment(vit_classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p37)",
   "language": "python",
   "name": "conda_tensorflow2_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
